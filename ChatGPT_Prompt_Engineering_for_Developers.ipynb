{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#!pip install --upgrade openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "2hVB6C_Du3qT",
        "outputId": "aba03a40-6275-4528-b043-d36ee683ba47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.96.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.14.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.7.9)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "#os.environ[\"OPENAI_API_KEY\"] = input(\"Enter your OpenAI API Key: \")\n",
        "os.environ[\"OPENROUTER_API_KEY\"] = input(\"Enter your OpenAI API Key: \")\n",
        "#openrouter api key: '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'\n",
        "os.environ"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "H-j9tl6UvIpG",
        "outputId": "33265d74-a7aa-49f3-a461-9f5a985b77dd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OpenAI API Key: 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\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "environ{'SHELL': '/bin/bash',\n",
              "        'NV_LIBCUBLAS_VERSION': '12.5.3.2-1',\n",
              "        'NVIDIA_VISIBLE_DEVICES': 'all',\n",
              "        'COLAB_JUPYTER_TRANSPORT': 'ipc',\n",
              "        'NV_NVML_DEV_VERSION': '12.5.82-1',\n",
              "        'NV_CUDNN_PACKAGE_NAME': 'libcudnn9-cuda-12',\n",
              "        'CGROUP_MEMORY_EVENTS': '/sys/fs/cgroup/memory.events /var/colab/cgroup/jupyter-children/memory.events',\n",
              "        'NV_LIBNCCL_DEV_PACKAGE': 'libnccl-dev=2.22.3-1+cuda12.5',\n",
              "        'NV_LIBNCCL_DEV_PACKAGE_VERSION': '2.22.3-1',\n",
              "        'VM_GCE_METADATA_HOST': '169.254.169.253',\n",
              "        'MODEL_PROXY_HOST': 'https://mp.kaggle.net',\n",
              "        'HOSTNAME': 'a74862009a4a',\n",
              "        'LANGUAGE': 'en_US',\n",
              "        'TBE_RUNTIME_ADDR': '172.28.0.1:8011',\n",
              "        'COLAB_TPU_1VM': '',\n",
              "        'GCE_METADATA_TIMEOUT': '3',\n",
              "        'NVIDIA_REQUIRE_CUDA': 'cuda>=12.5 brand=unknown,driver>=470,driver<471 brand=grid,driver>=470,driver<471 brand=tesla,driver>=470,driver<471 brand=nvidia,driver>=470,driver<471 brand=quadro,driver>=470,driver<471 brand=quadrortx,driver>=470,driver<471 brand=nvidiartx,driver>=470,driver<471 brand=vapps,driver>=470,driver<471 brand=vpc,driver>=470,driver<471 brand=vcs,driver>=470,driver<471 brand=vws,driver>=470,driver<471 brand=cloudgaming,driver>=470,driver<471 brand=unknown,driver>=535,driver<536 brand=grid,driver>=535,driver<536 brand=tesla,driver>=535,driver<536 brand=nvidia,driver>=535,driver<536 brand=quadro,driver>=535,driver<536 brand=quadrortx,driver>=535,driver<536 brand=nvidiartx,driver>=535,driver<536 brand=vapps,driver>=535,driver<536 brand=vpc,driver>=535,driver<536 brand=vcs,driver>=535,driver<536 brand=vws,driver>=535,driver<536 brand=cloudgaming,driver>=535,driver<536 brand=unknown,driver>=550,driver<551 brand=grid,driver>=550,driver<551 brand=tesla,driver>=550,driver<551 brand=nvidia,driver>=550,driver<551 brand=quadro,driver>=550,driver<551 brand=quadrortx,driver>=550,driver<551 brand=nvidiartx,driver>=550,driver<551 brand=vapps,driver>=550,driver<551 brand=vpc,driver>=550,driver<551 brand=vcs,driver>=550,driver<551 brand=vws,driver>=550,driver<551 brand=cloudgaming,driver>=550,driver<551',\n",
              "        'NV_LIBCUBLAS_DEV_PACKAGE': 'libcublas-dev-12-5=12.5.3.2-1',\n",
              "        'NV_NVTX_VERSION': '12.5.82-1',\n",
              "        'COLAB_JUPYTER_IP': '172.28.0.12',\n",
              "        'NV_CUDA_CUDART_DEV_VERSION': '12.5.82-1',\n",
              "        'NV_LIBCUSPARSE_VERSION': '12.5.1.3-1',\n",
              "        'COLAB_LANGUAGE_SERVER_PROXY_ROOT_URL': 'http://172.28.0.1:8013/',\n",
              "        'NV_LIBNPP_VERSION': '12.3.0.159-1',\n",
              "        'NCCL_VERSION': '2.22.3-1',\n",
              "        'KMP_LISTEN_PORT': '6000',\n",
              "        'TF_FORCE_GPU_ALLOW_GROWTH': 'true',\n",
              "        'ENV': '/root/.bashrc',\n",
              "        'PWD': '/',\n",
              "        'TBE_EPHEM_CREDS_ADDR': '172.28.0.1:8009',\n",
              "        'COLAB_LANGUAGE_SERVER_PROXY_REQUEST_TIMEOUT': '30s',\n",
              "        'TBE_CREDS_ADDR': '172.28.0.1:8008',\n",
              "        'NV_CUDNN_PACKAGE': 'libcudnn9-cuda-12=9.2.1.18-1',\n",
              "        'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility',\n",
              "        'COLAB_JUPYTER_TOKEN': '',\n",
              "        'LAST_FORCED_REBUILD': '20250623',\n",
              "        'NV_NVPROF_DEV_PACKAGE': 'cuda-nvprof-12-5=12.5.82-1',\n",
              "        'NV_LIBNPP_PACKAGE': 'libnpp-12-5=12.3.0.159-1',\n",
              "        'NV_LIBNCCL_DEV_PACKAGE_NAME': 'libnccl-dev',\n",
              "        'TCLLIBPATH': '/usr/share/tcltk/tcllib1.20',\n",
              "        'NV_LIBCUBLAS_DEV_VERSION': '12.5.3.2-1',\n",
              "        'NVIDIA_PRODUCT_NAME': 'CUDA',\n",
              "        'COLAB_KERNEL_MANAGER_PROXY_HOST': '172.28.0.12',\n",
              "        'UV_BUILD_CONSTRAINT': '',\n",
              "        'NV_LIBCUBLAS_DEV_PACKAGE_NAME': 'libcublas-dev-12-5',\n",
              "        'NV_CUDA_CUDART_VERSION': '12.5.82-1',\n",
              "        'COLAB_WARMUP_DEFAULTS': '1',\n",
              "        'HOME': '/root',\n",
              "        'LANG': 'en_US.UTF-8',\n",
              "        'CUDA_VERSION': '12.5.1',\n",
              "        'CLOUDSDK_CONFIG': '/content/.config',\n",
              "        'NV_LIBCUBLAS_PACKAGE': 'libcublas-12-5=12.5.3.2-1',\n",
              "        'NV_CUDA_NSIGHT_COMPUTE_DEV_PACKAGE': 'cuda-nsight-compute-12-5=12.5.1-1',\n",
              "        'UV_SYSTEM_PYTHON': 'true',\n",
              "        'COLAB_RELEASE_TAG': 'release-colab_20250729-060053_RC00',\n",
              "        'KMP_TARGET_PORT': '9000',\n",
              "        'KMP_EXTRA_ARGS': '--logtostderr --listen_host=172.28.0.12 --target_host=172.28.0.12 --tunnel_background_save_url=https://colab.research.google.com/tun/m/cc48301118ce562b961b3c22d803539adc1e0c19/m-s-uavsonxparwu --tunnel_background_save_delay=10s --tunnel_periodic_background_save_frequency=30m0s --enable_output_coalescing=true --output_coalescing_required=true ',\n",
              "        'UV_INSTALL_DIR': '/usr/local/bin',\n",
              "        'NV_LIBNPP_DEV_PACKAGE': 'libnpp-dev-12-5=12.3.0.159-1',\n",
              "        'COLAB_LANGUAGE_SERVER_PROXY_LSP_DIRS': '/datalab/web/pyright/typeshed-fallback/stdlib,/usr/local/lib/python3.10/dist-packages',\n",
              "        'NV_LIBCUBLAS_PACKAGE_NAME': 'libcublas-12-5',\n",
              "        'COLAB_KERNEL_MANAGER_PROXY_PORT': '6000',\n",
              "        'CLOUDSDK_PYTHON': 'python3',\n",
              "        'NV_LIBNPP_DEV_VERSION': '12.3.0.159-1',\n",
              "        'NO_GCE_CHECK': 'False',\n",
              "        'PYTHONPATH': '/env/python',\n",
              "        'NV_LIBCUSPARSE_DEV_VERSION': '12.5.1.3-1',\n",
              "        'LIBRARY_PATH': '/usr/local/cuda/lib64/stubs',\n",
              "        'NV_CUDNN_VERSION': '9.2.1.18-1',\n",
              "        'SHLVL': '0',\n",
              "        'NV_CUDA_LIB_VERSION': '12.5.1-1',\n",
              "        'COLAB_LANGUAGE_SERVER_PROXY': '/usr/colab/bin/language_service',\n",
              "        'NVARCH': 'x86_64',\n",
              "        'UV_CONSTRAINT': '',\n",
              "        'PYTHONUTF8': '1',\n",
              "        'NV_CUDNN_PACKAGE_DEV': 'libcudnn9-dev-cuda-12=9.2.1.18-1',\n",
              "        'NV_LIBNCCL_PACKAGE': 'libnccl2=2.22.3-1+cuda12.5',\n",
              "        'LD_LIBRARY_PATH': '/usr/local/nvidia/lib:/usr/local/nvidia/lib64',\n",
              "        'COLAB_GPU': '',\n",
              "        'NV_CUDA_NSIGHT_COMPUTE_VERSION': '12.5.1-1',\n",
              "        'GCS_READ_CACHE_BLOCK_SIZE_MB': '16',\n",
              "        'NV_NVPROF_VERSION': '12.5.82-1',\n",
              "        'LC_ALL': 'en_US.UTF-8',\n",
              "        'COLAB_FILE_HANDLER_ADDR': 'localhost:3453',\n",
              "        'PATH': '/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin',\n",
              "        'NV_LIBNCCL_PACKAGE_NAME': 'libnccl2',\n",
              "        'COLAB_DEBUG_ADAPTER_MUX_PATH': '/usr/local/bin/dap_multiplexer',\n",
              "        'NV_LIBNCCL_PACKAGE_VERSION': '2.22.3-1',\n",
              "        'PYTHONWARNINGS': 'ignore:::pip._internal.cli.base_command',\n",
              "        'DEBIAN_FRONTEND': 'noninteractive',\n",
              "        'COLAB_BACKEND_VERSION': 'next',\n",
              "        'OLDPWD': '/',\n",
              "        '_PYVIZ_COMMS_INSTALLED': '1',\n",
              "        'PYDEVD_USE_FRAME_EVAL': 'NO',\n",
              "        'JPY_PARENT_PID': '87',\n",
              "        'TERM': 'xterm-color',\n",
              "        'CLICOLOR': '1',\n",
              "        'PAGER': 'cat',\n",
              "        'GIT_PAGER': 'cat',\n",
              "        'MPLBACKEND': 'module://matplotlib_inline.backend_inline',\n",
              "        'ENABLE_DIRECTORYPREFETCHER': '1',\n",
              "        'USE_AUTH_EPHEM': '1',\n",
              "        'COLAB_NOTEBOOK_ID': '1uDGJ01VeWL7YxXs1sQFf8nwR7b1Bh4CY',\n",
              "        'OPENROUTER_API_KEY': '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'}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "beXhtcaaoet6"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "#client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
        "client = OpenAI(base_url=\"https://openrouter.ai/api/v1\", api_key=os.environ[\"OPENROUTER_API_KEY\"])\n",
        "\n",
        "def get_completion(prompt, model=\"deepseek/deepseek-r1:free\"):\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0,\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Input text\n",
        "text = \"\"\"\n",
        "You should express what you want a model to do by providing instructions that are as clear and specific as you can possibly make them. \\\n",
        "This will guide the model towards the desired output, and reduce the chances of receiving irrelevant or incorrect responses. \\\n",
        "Don't confuse writing a clear prompt with writing a short prompt. In many cases, longer prompts provide more clarity and context for the model, which can lead to more detailed and relevant outputs.\n",
        "\"\"\"\n",
        "\n",
        "# Prompt to summarize\n",
        "prompt = f\"\"\"\n",
        "Summarize the text delimited by triple backticks into a single sentence.\n",
        "```{text}```\n",
        "\"\"\"\n",
        "\n",
        "# Get response\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2pNnvgco91i",
        "outputId": "eed15cb2-d51d-4c17-d255-24241b1260d3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To ensure accurate and relevant outputs from a model, provide clear, specific, and sufficiently detailed instructions, prioritizing clarity and context over brevity, as longer prompts often enhance guidance and reduce errors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Generate a list of three made-up book titles along with their authors and genres. \\\n",
        "Provide them in JSON format with the following keys:\n",
        "book_id, title, author, genre.\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeIjutlpqDOZ",
        "outputId": "c66453f3-ad9c-48d9-dcda-4cbd73e559e1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```json\n",
            "[\n",
            "  {\n",
            "    \"book_id\": 1,\n",
            "    \"title\": \"The Crystal Labyrinth of Astral Veils\",\n",
            "    \"author\": \"Lirael Thornweave\",\n",
            "    \"genre\": \"Fantasy\"\n",
            "  },\n",
            "  {\n",
            "    \"book_id\": 2,\n",
            "    \"title\": \"The Quantum Paradox\",\n",
            "    \"author\": \"Jaxon Vey\",\n",
            "    \"genre\": \"Science Fiction\"\n",
            "  },\n",
            "  {\n",
            "    \"book_id\": 3,\n",
            "    \"title\": \"The Whispering Shadows of Hollowbrook\",\n",
            "    \"author\": \"Elara Caine\",\n",
            "    \"genre\": \"Mystery\"\n",
            "  }\n",
            "]\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_1 = \"\"\"\n",
        "Making a cup of tea is easy! First, you need to get some water boiling. While that's happening,\n",
        "grab a cup and put a tea bag in it. Once the water is hot enough, just pour it over the tea bag.\n",
        "Let it sit for a bit so the tea can steep. After a few minutes, take out the tea bag.\n",
        "If you like, you can add some sugar or milk to taste. And that's it! You've got yourself a delicious cup of tea to enjoy.\n",
        "\"\"\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "You will be provided with text delimited by triple quotes.\n",
        "\n",
        "If it contains a sequence of instructions,\n",
        "re-write those instructions in the following format:\n",
        "\n",
        "Step 1 - ...\n",
        "Step 2 - ...\n",
        "...\n",
        "Step N - ...\n",
        "\n",
        "If the text does not contain a sequence of instructions,\n",
        "then simply write \\\"No steps provided.\\\"\n",
        "\n",
        "```{text_1}```\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "\n",
        "print(\"Completion for Text 1:\")\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tCvS_b1rVDc",
        "outputId": "0fbc7ae7-df7c-40b4-94d8-f5dcb60c2cce"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion for Text 1:\n",
            "Step 1 - Boil water in a kettle or pot.  \n",
            "Step 2 - While water heats, take a cup and place a tea bag inside it.  \n",
            "Step 3 - Pour the hot water into the cup, covering the tea bag completely.  \n",
            "Step 4 - Allow the tea to steep for 3–5 minutes.  \n",
            "Step 5 - Remove the tea bag from the cup.  \n",
            "Step 6 - Add sugar, milk, or other flavorings to taste (optional).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_2 = \"\"\"\n",
        "The sun is shining brightly today, and the birds are singing. It's a beautiful day to go for a walk in the park.\n",
        "The flowers are blooming, and the trees are swaying gently in the breeze.\n",
        "People are out and about, enjoying the lovely weather.\n",
        "Some are having picnics, while others are playing games or simply relaxing on the grass.\n",
        "It's a perfect day to spend time outdoors and appreciate the beauty of nature.\n",
        "\"\"\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "You will be provided with text delimited by triple quotes.\n",
        "\n",
        "If it contains a sequence of instructions,\n",
        "re-write those instructions in the following format:\n",
        "\n",
        "Step 1 - ...\n",
        "Step 2 - ...\n",
        "...\n",
        "Step N - ...\n",
        "\n",
        "If the text does not contain a sequence of instructions,\n",
        "then simply write \\\"No steps provided.\\\"\n",
        "\n",
        "```{text_2}```\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "\n",
        "print(\"Completion for Text 2:\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcvtOOHBskQ-",
        "outputId": "f2055737-bfea-4099-bea9-e68924316abc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion for Text 2:\n",
            "No steps provided.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "In a charming village, siblings Jack and Jill set out on a quest to fetch water from a hilltop well.\n",
        "As they climbed, singing joyfully, misfortune struck—Jack tripped on a stone and tumbled down the hill, with Jill following suit.\n",
        "Though slightly battered, the pair returned home to comforting embraces.\n",
        "Despite the mishap, their adventurous spirits remained undimmed, and they continued exploring with delight.\n",
        "\"\"\"\n",
        "\n",
        "prompt_1 = f\"\"\"\n",
        "Perform the following actions:\n",
        "\n",
        "1. Summarize the following text delimited by triple backticks with 1 sentence.\n",
        "2. Translate the summary into French.\n",
        "3. List each name in the French summary.\n",
        "4. Output a JSON object that contains the following keys: french_summary, num_names.\n",
        "\n",
        "Separate your answers with line breaks.\n",
        "\n",
        "Text:\n",
        "{text}\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt_1)\n",
        "\n",
        "print(\"Completion for prompt 1:\")\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2qA1ohWOTOY",
        "outputId": "55acff18-d241-4c80-9436-0c9bf6b16d40"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion for prompt 1:\n",
            "Two siblings, Jack and Jill, experience a minor accident while fetching water from a hilltop well but return home comforted and remain eager for future adventures.  \n",
            "\n",
            "Deux frères et sœurs, Jack et Jill, subissent un accident mineur en allant chercher de l'eau à un puits au sommet d'une colline mais rentrent chez eux réconfortés et restent enthousiastes à l'idée de futures aventures.  \n",
            "\n",
            "Jack, Jill  \n",
            "\n",
            "{  \n",
            "  \"french_summary\": \"Deux frères et sœurs, Jack et Jill, subissent un accident mineur en allant chercher de l'eau à un puits au sommet d'une colline mais rentrent chez eux réconfortés et restent enthousiastes à l'idée de futures aventures.\",  \n",
            "  \"num_names\": 2  \n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Tell me about AeroGlide UltraSlim Smart Toothbrush by Boie\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uII8NFfGPCVo",
        "outputId": "14c120cd-0977-42a1-e800-89d6ea77394c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The **AeroGlide UltraSlim Smart Toothbrush by Boie** is a manual toothbrush designed with a focus on sustainability, ergonomics, and innovative features. Here's a detailed overview based on available information and typical characteristics of Boie products:\n",
            "\n",
            "### Key Features:\n",
            "1. **Ultra-Slim Design**: \n",
            "   - The brush head and handle are notably slim, enhancing maneuverability and access to hard-to-reach areas, ideal for users with smaller mouths or those seeking precision.\n",
            "\n",
            "2. **Eco-Friendly Materials**:\n",
            "   - Made from **recyclable materials** (likely BPA-free and antimicrobial), aligning with Boie's commitment to sustainability. The handle is durable and designed for long-term use with replaceable heads.\n",
            "\n",
            "3. **Smart Features**:\n",
            "   - While specifics may vary, \"Smart\" could refer to **built-in timers** (e.g., pulsating lights or tactile cues) to encourage 2-minute brushing sessions, or a **pressure sensor** to prevent gum damage from aggressive brushing. Note that Boie typically focuses on manual brushes, so advanced Bluetooth connectivity is unlikely.\n",
            "\n",
            "4. **Bristle Technology**:\n",
            "   - Uses **flexible, curved bristles** made from **thermoplastic elastomer** (TPE), which resists bacterial growth and dries faster than nylon. These bristles are gentle on gums while effectively cleaning teeth.\n",
            "\n",
            "5. **Replaceable Heads**:\n",
            "   - Reduces waste by allowing users to keep the handle and swap heads (lasting ~6 months each). Often sold in recyclable packaging.\n",
            "\n",
            "6. **Ergonomics**:\n",
            "   - The slim, lightweight handle is designed for a comfortable grip, though some users might find it too slender if accustomed to bulkier handles.\n",
            "\n",
            "### Pricing & Availability:\n",
            "- **Estimated Cost**: $10–20 for the handle, with replacement heads sold separately (typically $5–10 per head).\n",
            "- Sold via Boie’s website, eco-conscious retailers, or online platforms like Amazon.\n",
            "\n",
            "### User Feedback:\n",
            "- **Pros**: Praised for sustainability, comfort, and effective cleaning. The slim design is often highlighted as a standout feature.\n",
            "- **Cons**: Some users may prefer firmer bristles or find the handle too thin. The \"smart\" features might be more minimalist compared to electric competitors.\n",
            "\n",
            "### Considerations:\n",
            "- Boie emphasizes **hygiene and environmental impact**, making this brush a strong choice for eco-aware consumers.\n",
            "- If \"smart\" features are a priority, verify specifics directly from Boie, as the term may refer to design efficiency rather than digital connectivity.\n",
            "\n",
            "For the most accurate details, check Boie’s official product page or recent reviews.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### ChatBot\n",
        "\n",
        "def get_completion(prompt, model=\"deepseek/deepseek-r1:free\"):\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0,\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "def get_completion_from_messages(messages,model=\"deepseek/deepseek-r1:free\",temperature=0):\n",
        "  response = client.chat.completions.create(\n",
        "      model=model,\n",
        "      messages=messages,\n",
        "      temperature=temperature,\n",
        "  )\n",
        "  return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "-hRnwk8Zcc7S"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages =  [\n",
        "{'role':'system', 'content':'You are an assistant that speaks like Shakespeare.'},\n",
        "{'role':'user', 'content':'tell me a joke'},\n",
        "{'role':'assistant', 'content':'Why did the chicken cross the road'},\n",
        "{'role':'user', 'content':'I don\\'t know'}  ]"
      ],
      "metadata": {
        "id": "NnoYII9hdi-e"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion_from_messages(messages,temperature=1)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whFzN8FQey27",
        "outputId": "d100d67b-2135-459c-eb81-380bef7d3dde"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ah, verily, 'tis simple, good soul! The fowl, in manner bold and sprightly, didst traverse the thoroughfare to proclaim his disdain for the plight of mortal pigeons—aye, to mock those earthbound wingèd kin who ne'er dare dream beyond the dust.  \n",
            "But lo, perchance the road was but a stage, and the bird a player brief, who sought applause by strutting 'cross Fate's path. Alas! The jest—for this is the rub—is but an old and hollow drum: “To reach the other side” doth fall as flat as Bottom’s bardic play. Yet fret not! Let us to better mirth:  \n",
            "Why doth the raven mimic yon writing desk? “Because Poe wrote on both—though neither one could rhyme!”  \n",
            "🙃\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages =  [\n",
        "{'role':'system', 'content':'You are friendly chatbot.'},\n",
        "{'role':'user', 'content':'Hi, my name is Isa'}  ]\n",
        "response = get_completion_from_messages(messages, temperature=1)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCN57VEyfPvc",
        "outputId": "24519c3a-82f5-4d59-9dfa-14add1f284bf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hi, Isa! 👋 It's lovely to meet you. How can I help you today? 😊\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages =  [\n",
        "{'role':'system', 'content':'You are friendly chatbot.'},\n",
        "{'role':'user', 'content':'Yes,  can you remind me, What is my name?'}  ]\n",
        "response = get_completion_from_messages(messages, temperature=1)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seAVsCfogYRC",
        "outputId": "03483827-09da-41ff-b4cb-f972d912718b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "As an AI assistant, I don't have access to personal information about individuals unless explicitly shared during our conversation. Your privacy is important, and I don't store personal data between interactions. Please feel free to let me know how you'd like to be addressed, or ask anything else! 😊\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages =  [\n",
        "{'role':'system', 'content':'You are friendly chatbot.'},\n",
        "{'role':'user', 'content':'Hi, my name is Isa'},\n",
        "{'role':'assistant', 'content': \"Hi Isa! It's nice to meet you. \\\n",
        "Is there anything I can help you with today?\"},\n",
        "{'role':'user', 'content':'Yes, you can remind me, What is my name?'}  ]\n",
        "response = get_completion_from_messages(messages, temperature=1)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQi8iXWfghAZ",
        "outputId": "2b2d3dda-d44c-48b9-ab49-4cd96ee07534"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your name is **Isa**! 😊 Is there anything else you'd like help with?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **OrderBot**"
      ],
      "metadata": {
        "id": "5x1PGzHqg2R-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "y7CYaCzsgtro",
        "outputId": "c436dac1-b22e-44d1-fd6b-21c515d6ae62"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.38.2)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.116.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.6.1)\n",
            "Requirement already satisfied: gradio-client==1.11.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.11.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.11.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.12.5)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.47.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.14.1)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.35.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.11.0->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.11.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import requests\n",
        "import os"
      ],
      "metadata": {
        "id": "h0j0ralYhNKd"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### ChatBot\n",
        "\n",
        "def get_completion(prompt, model=\"deepseek/deepseek-r1:free\"):\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0,\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "def get_completion_from_messages(messages,model=\"deepseek/deepseek-r1:free\",temperature=0):\n",
        "  response = client.chat.completions.create(\n",
        "      model=model,\n",
        "      messages=messages,\n",
        "      temperature=temperature,\n",
        "  )\n",
        "  return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "7J3-0v31hdib"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initial system prompt (pizza bot instructions)\n",
        "system_prompt = {\n",
        "    \"role\": \"system\",\n",
        "    \"content\": \"\"\"\n",
        "    You are OrderBot, an automated service to collect orders for a pizza restaurant.\n",
        "    You greet the customer, take their order, confirm pickup/delivery, ask for extras, and finalize payment.\n",
        "    Clarify all menu details. Menu includes:\n",
        "    pepperoni pizza 12.95, 10.00, 7.00,\n",
        "    cheese pizza 10.95, 9.25, 6.50,\n",
        "    eggplant pizza 11.95, 9.75, 6.75,\n",
        "    fries 4.50, 3.50, greek salad 7.25,\n",
        "    Toppings: extra cheese 2.00, mushrooms 1.50, sausage 3.00, canadian bacon 3.50, AI sauce 1.50, peppers 1.00,\n",
        "    Drinks: coke 3.00, 2.00, 1.00, sprite 3.00, 2.00, 1.00, bottled water 5.00.\n",
        "    \"\"\"\n",
        "}\n"
      ],
      "metadata": {
        "id": "veVv8EswlBHc"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot_gradio(user_message, history):\n",
        "    messages = [system_prompt]\n",
        "\n",
        "    # history format is now [{'role': 'user', 'content': 'Hi'}, {'role': 'assistant', 'content': 'Hello!'}]\n",
        "    for m in history:\n",
        "        messages.append(m)\n",
        "\n",
        "    # Add current user message\n",
        "    messages.append({\"role\": \"user\", \"content\": user_message})\n",
        "\n",
        "    # Get response from model\n",
        "    try:\n",
        "        response = get_completion_from_messages(messages)\n",
        "    except Exception as e:\n",
        "        response = f\"Error: {e}\"\n",
        "\n",
        "    # Update history\n",
        "    history.append({\"role\": \"user\", \"content\": user_message})\n",
        "    history.append({\"role\": \"assistant\", \"content\": response})\n",
        "\n",
        "    return history, history\n"
      ],
      "metadata": {
        "id": "Gy12q_uwlDFC"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"### 🍕 Pizza OrderBot - powered by OpenRouter AI\")\n",
        "    chatbot = gr.Chatbot(type='messages')\n",
        "    msg = gr.Textbox(placeholder=\"What's your order?\")\n",
        "    state = gr.State([])\n",
        "\n",
        "    msg.submit(chatbot_gradio, [msg, state], [chatbot, state])\n"
      ],
      "metadata": {
        "id": "pe4xIwA6lGAw"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "i68a12h0lJkF",
        "outputId": "63d63e26-d26f-4efd-dced-994240e03080"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://db5b6f4d3c9980cdc7.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://db5b6f4d3c9980cdc7.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m5t53zg_lrrb"
      },
      "execution_count": 22,
      "outputs": []
    }
  ]
}